# Copyright (c) 2018-2023, NVIDIA Corporation
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
#
# 1. Redistributions of source code must retain the above copyright notice, this
#    list of conditions and the following disclaimer.
#
# 2. Redistributions in binary form must reproduce the above copyright notice,
#    this list of conditions and the following disclaimer in the documentation
#    and/or other materials provided with the distribution.
#
# 3. Neither the name of the copyright holder nor the names of its
#    contributors may be used to endorse or promote products derived from
#    this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

import numpy as np
import os
import torch

from isaacgym import gymtorch
from isaacgym import gymapi
from isaacgymenvs.utils.torch_jit_utils import scale, unscale, quat_mul, quat_conjugate, quat_from_angle_axis, \
    to_torch, get_axis_params, torch_rand_float, tensor_clamp, compute_heading_and_up, compute_rot, normalize_angle

from isaacgymenvs.tasks.base.vec_task import VecTask


class G1Robot(VecTask):

    def __init__(self,
                 cfg,
                 rl_device,
                 sim_device,
                 graphics_device_id,
                 headless,
                 virtual_screen_capture,
                 force_render):
        # â€”â€”â€” å‚æ•°é…ç½® â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        self.debug_viz = cfg["env"].get("enableDebugVis", False)
        self.cfg                          = cfg
        self.randomization_params         = cfg["task"]["randomization_params"]
        self.randomize                    = cfg["task"]["randomize"]
        self.dof_vel_scale                = cfg["env"]["dofVelocityScale"]
        self.angular_velocity_scale       = cfg["env"].get("angularVelocityScale", 0.1)
        self.contact_force_scale          = cfg["env"]["contactForceScale"]
        self.power_scale                  = cfg["env"]["powerScale"]
        self.heading_weight               = cfg["env"]["headingWeight"]
        self.up_weight                    = cfg["env"]["upWeight"]
        self.actions_cost_scale           = cfg["env"]["actionsCost"]
        self.energy_cost_scale            = cfg["env"]["energyCost"]
        self.joints_at_limit_cost_scale   = cfg["env"]["jointsAtLimitCost"]
        self.death_cost                   = cfg["env"]["deathCost"]
        self.termination_height           = cfg["env"]["terminationHeight"]
        plane = cfg["env"]["plane"]
        self.plane_static_friction        = plane["staticFriction"]
        self.plane_dynamic_friction       = plane["dynamicFriction"]
        self.plane_restitution            = plane["restitution"]
        self.max_episode_length           = cfg["env"]["episodeLength"]
        # å¼ºåˆ¶æŒ‡å®š obs/action ç»´åº¦
        cfg["env"]["numObservations"]     = 188
        cfg["env"]["numActions"]          = 41
        
        
        # â€”â€”â€” çˆ¶ç±»åˆå§‹åŒ– â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        super().__init__(config=self.cfg,
                         rl_device=rl_device,
                         sim_device=sim_device,
                         graphics_device_id=graphics_device_id,
                         headless=headless,
                         virtual_screen_capture=virtual_screen_capture,
                         force_render=force_render)

        # å¯è§†åŒ–æ‘„åƒæœºï¼ˆå¯é€‰ï¼‰
        if self.viewer is not None:
            cam_pos    = gymapi.Vec3(10.0, -5.0, 2.4)
            cam_target = gymapi.Vec3(0.0, 0.0, 1.0)
            self.gym.viewer_camera_look_at(self.viewer, None, cam_pos, cam_target)

        # â€”â€”â€” è·å–å¹¶åŒ…è£… GPU å¼ é‡ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        actor_root_state = self.gym.acquire_actor_root_state_tensor(self.sim)
        dof_state_tensor = self.gym.acquire_dof_state_tensor(self.sim)

        # åˆšä½“åŠ›ä¼ æ„Ÿå™¨ï¼šå·¦å³è„šå„ 1ï¼Œå…± 2Ã—6=12
        sensor_tensor   = self.gym.acquire_force_sensor_tensor(self.sim)
        sensors_per_env = 2
        if sensor_tensor is None:
            # å¦‚æœæ²¡åˆ›å»ºæˆ–æ— æ•ˆï¼Œå°±é€€å›é›¶å¼ é‡
            self.vec_sensor_tensor = torch.zeros(
                self.num_envs, sensors_per_env * 6,
                device=self.device, dtype=torch.float32
            )
        else:
            self.vec_sensor_tensor = gymtorch.wrap_tensor(sensor_tensor)\
                                         .view(self.num_envs, sensors_per_env * 6)

        # å…³èŠ‚æ‰­çŸ©å¼ é‡
        dof_force_tensor = self.gym.acquire_dof_force_tensor(self.sim)
        self.dof_force_tensor = gymtorch.wrap_tensor(dof_force_tensor)\
                                         .view(self.num_envs, self.num_dof)

        # åˆ·æ–°å¹¶ä¿å­˜ root/dof çŠ¶æ€
        self.gym.refresh_dof_state_tensor(self.sim)
        self.gym.refresh_actor_root_state_tensor(self.sim)
        self.root_states         = gymtorch.wrap_tensor(actor_root_state)
        self.initial_root_states = self.root_states.clone()
        # æ¸…é™¤åˆå§‹æ—‹è½¬é€Ÿåº¦
        self.initial_root_states[:, 7:13] = 0

        # æ‹†åˆ† dof_pos/dof_vel
        self.dof_state = gymtorch.wrap_tensor(dof_state_tensor)
        self.dof_pos   = self.dof_state.view(self.num_envs, self.num_dof, 2)[..., 0]
        self.dof_vel   = self.dof_state.view(self.num_envs, self.num_dof, 2)[..., 1]

        # åˆå§‹å…³èŠ‚ä½ç½®ï¼ˆç½®äºä¸Šä¸‹é™æˆ– 0ï¼‰
        self.initial_dof_pos = torch.zeros_like(self.dof_pos, device=self.device)
        zero_tensor = torch.tensor([0.0], device=self.device)
        self.initial_dof_pos = torch.where(
            self.dof_limits_lower > zero_tensor,
            self.dof_limits_lower,
            torch.where(self.dof_limits_upper < zero_tensor,
                        self.dof_limits_upper,
                        self.initial_dof_pos)
        )
        self.initial_dof_vel = torch.zeros_like(self.dof_vel, device=self.device)

        # åç»­ observations æ„é€ æ‰€éœ€å¸¸é‡
        self.up_vec          = to_torch(get_axis_params(1., self.up_axis_idx),
                                        device=self.device).repeat(self.num_envs, 1)
        self.heading_vec     = to_torch([1, 0, 0], device=self.device)\
                                        .repeat(self.num_envs, 1)
        self.inv_start_rot   = quat_conjugate(self.start_rotation)\
                                        .repeat(self.num_envs, 1)
        self.basis_vec0      = self.heading_vec.clone()
        self.basis_vec1      = self.up_vec.clone()
        self.targets         = to_torch([1000, 0, 0], device=self.device)\
                                        .repeat(self.num_envs, 1)
        self.target_dirs     = to_torch([1, 0, 0], device=self.device)\
                                        .repeat(self.num_envs, 1)
        self.dt              = self.cfg["sim"]["dt"]
        self.potentials      = to_torch([-1000. / self.dt], device=self.device)\
                                        .repeat(self.num_envs)
        self.prev_potentials = self.potentials.clone()
        
    def create_sim(self):
        self.up_axis_idx = 2 # index of up axis: Y=1, Z=2
        self.sim = super().create_sim(self.device_id, self.graphics_device_id, self.physics_engine, self.sim_params)

        self._create_ground_plane()
        self._create_envs(self.num_envs, self.cfg["env"]['envSpacing'], int(np.sqrt(self.num_envs)))

        # If randomizing, apply once immediately on startup before the fist sim step
        if self.randomize:
            self.apply_randomizations(self.randomization_params)

    def _create_ground_plane(self):
        plane_params = gymapi.PlaneParams()
        plane_params.normal = gymapi.Vec3(0.0, 0.0, 1.0)
        plane_params.static_friction = self.plane_static_friction
        plane_params.dynamic_friction = self.plane_dynamic_friction
        plane_params.restitution = self.plane_restitution
        self.gym.add_ground(self.sim, plane_params)

    def _create_envs(self, num_envs, spacing, num_per_row):
        # â€”â€”â€” è®¡ç®—ç¯å¢ƒé˜µåˆ—èŒƒå›´ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        lower = gymapi.Vec3(-spacing, -spacing, 0.0)
        upper = gymapi.Vec3( spacing,  spacing, spacing)

        # â€”â€”â€” èµ„äº§è·¯å¾„ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        asset_root = os.path.join(os.path.dirname(__file__), '../../assets')
        asset_file = "mjcf/g1_description/g1_29dof_lock_waist_with_hand_rev_1_0.xml"
        if "asset" in self.cfg["env"]:
            asset_file = self.cfg["env"]["asset"].get("assetFileName", asset_file)
        asset_path = os.path.join(asset_root, asset_file)
        asset_root = os.path.dirname(asset_path)
        asset_file = os.path.basename(asset_path)

        # â€”â€”â€” åŠ è½½èµ„äº§ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        options = gymapi.AssetOptions()
        options.angular_damping        = 0.01
        options.max_angular_velocity   = 100.0
        options.default_dof_drive_mode = gymapi.DOF_MODE_NONE
        humanoid_asset = self.gym.load_asset(self.sim, asset_root, asset_file, options)

        # â€”â€”â€” è¯»å– actuator å‚æ•° â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        props = self.gym.get_asset_actuator_properties(humanoid_asset)
        motor_efforts = [p.motor_effort for p in props]
        self.max_motor_effort = max(motor_efforts)
        self.motor_efforts    = to_torch(motor_efforts, device=self.device)

        # â€”â€”â€” åˆ›å»ºåˆšä½“åŠ›ä¼ æ„Ÿå™¨ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        sensor_pose = gymapi.Transform()
        right_idx   = self.gym.find_asset_rigid_body_index(humanoid_asset, "right_ankle_roll_link")
        left_idx    = self.gym.find_asset_rigid_body_index(humanoid_asset, "left_ankle_roll_link")
        self.gym.create_asset_force_sensor(humanoid_asset, right_idx, sensor_pose)
        self.gym.create_asset_force_sensor(humanoid_asset, left_idx,  sensor_pose)

        # â€”â€”â€” ä¿å­˜ DoF/Body æ•°é‡ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        self.num_bodies = self.gym.get_asset_rigid_body_count(humanoid_asset)
        self.num_dof    = self.gym.get_asset_dof_count(humanoid_asset)
        self.num_joints = self.gym.get_asset_joint_count(humanoid_asset)

        # â€”â€”â€” åˆå§‹æ”¾ç½® â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        start_pose = gymapi.Transform()
        start_pose.p = gymapi.Vec3(*get_axis_params(0.7, self.up_axis_idx))
        start_pose.r = gymapi.Quat(0.0, 0.0, 0.0, 1.0)
        self.start_rotation = torch.tensor(
            [start_pose.r.x, start_pose.r.y, start_pose.r.z, start_pose.r.w],
            device=self.device
        )

        # â€”â€”â€” åˆ›å»ºå„ç¯å¢ƒå®ä¾‹ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        self.humanoid_handles = []
        self.envs             = []
        for i in range(self.num_envs):
            env_ptr = self.gym.create_env(self.sim, lower, upper, num_per_row)
            handle  = self.gym.create_actor(env_ptr, humanoid_asset, start_pose, "humanoid", i, 0, 0)
            self.gym.enable_actor_dof_force_sensors(env_ptr, handle)
            # å¯è§†åŒ–ä¸Šè‰²ï¼ˆå¯é€‰ï¼‰
            for j in range(self.num_bodies):
                self.gym.set_rigid_body_color(env_ptr, handle, j,
                                              gymapi.MESH_VISUAL,
                                              gymapi.Vec3(0.97, 0.38, 0.06))
            self.envs.append(env_ptr)
            self.humanoid_handles.append(handle)

        # â€”â€”â€” è¯»å–å¹¶ä¿å­˜å…³èŠ‚é™ä½ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        dof_prop = self.gym.get_actor_dof_properties(env_ptr, handle)
        lowers, uppers = [], []
        for j in range(self.num_dof):
            low, high = dof_prop['lower'][j], dof_prop['upper'][j]
            if low > high:
                lowers.append(high); uppers.append(low)
            else:
                lowers.append(low);   uppers.append(high)
        self.dof_limits_lower = to_torch(lowers, device=self.device)
        self.dof_limits_upper = to_torch(uppers, device=self.device)

        # â€”â€”â€” æ–°å¢ï¼šå¯¹é”æ­»å…³èŠ‚åšå®‰å…¨æ‰©å±• â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        # æ ‡è®°é”æ­»å…³èŠ‚ï¼ˆupper == lowerï¼‰
        self.locked_dofs = (self.dof_limits_upper == self.dof_limits_lower)
        eps = 1e-6  # æå°å€¼
        # æ„é€  safe_lower ä¸ safe_upperï¼Œç”¨äºåç»­å½’ä¸€åŒ–æ—¶é¿å…é™¤é›¶
        self.safe_lower = self.dof_limits_lower.clone()
        self.safe_upper = self.dof_limits_upper.clone()
        self.safe_upper[self.locked_dofs] += eps

    def compute_reward(self, actions):
        self.rew_buf[:], self.reset_buf = compute_humanoid_reward(
            self.obs_buf,
            self.reset_buf,
            self.progress_buf,
            self.actions,
            self.up_weight,
            self.heading_weight,
            self.potentials,
            self.prev_potentials,
            self.actions_cost_scale,
            self.energy_cost_scale,
            self.joints_at_limit_cost_scale,
            self.max_motor_effort,
            self.motor_efforts,
            self.termination_height,
            self.death_cost,
            self.max_episode_length
        )

    def compute_observations(self):
        self.gym.refresh_dof_state_tensor(self.sim)
        self.gym.refresh_actor_root_state_tensor(self.sim)

        self.gym.refresh_force_sensor_tensor(self.sim)

        self.gym.refresh_dof_force_tensor(self.sim)
        self.obs_buf[:], self.potentials[:], self.prev_potentials[:], self.up_vec[:], self.heading_vec[:] = compute_humanoid_observations(
            self.obs_buf, self.root_states, self.targets, self.potentials,
            self.inv_start_rot, self.dof_pos, self.dof_vel, self.dof_force_tensor,
            self.dof_limits_lower, self.dof_limits_upper, self.dof_vel_scale,
            self.vec_sensor_tensor, self.actions, self.dt, self.contact_force_scale, self.angular_velocity_scale,
            self.basis_vec0, self.basis_vec1)

    def reset_idx(self, env_ids):
        if self.randomize:
            self.apply_randomizations(self.randomization_params)

        # 1) ä¸ºæ‰€é€‰ env é‡‡æ ·åˆå§‹ä½ç½®å’Œé€Ÿåº¦æ‰°åŠ¨
        positions = torch_rand_float(
            -0.2, 0.2,
            (len(env_ids), self.num_dof),
            device=self.device
        )
        velocities = torch_rand_float(
            -0.1, 0.1,
            (len(env_ids), self.num_dof),
            device=self.device
        )

        # 2) æ›´æ–° dof_pos / dof_vel
        self.dof_pos[env_ids] = tensor_clamp(
            self.initial_dof_pos[env_ids] + positions,
            self.dof_limits_lower, self.dof_limits_upper
        )
        self.dof_vel[env_ids] = velocities

        # 3) æ£€æŸ¥æ•°å€¼åˆæ³•æ€§
        assert torch.all(torch.isfinite(self.dof_pos[env_ids])), "âŒ dof_pos has NaNs!"
        assert torch.all(torch.isfinite(self.dof_vel[env_ids])), "âŒ dof_vel has NaNs!"

        # 4) é‡ç½®æ ¹çŠ¶æ€
        env_ids_int32 = env_ids.to(dtype=torch.int32)
        new_roots = self.initial_root_states[env_ids].clone()
        assert torch.all(torch.isfinite(new_roots)), "âŒ initial_root_states has NaNs!"
        self.root_states[env_ids] = new_roots
        self.gym.set_actor_root_state_tensor_indexed(
            self.sim,
            gymtorch.unwrap_tensor(self.root_states),
            gymtorch.unwrap_tensor(env_ids_int32),
            len(env_ids_int32)
        )

        # 5) æ­£ç¡®åœ°æŠŠ dof_pos å’Œ dof_vel å†™å›åˆ° self.dof_stateï¼ˆshape = [num_envs, num_dof, 2]ï¼‰
        #    â€”â€”â€” æ³¨æ„ç´¢å¼•ç¬¬ 2 ç»´ channelï¼Œè€Œä¸æ˜¯ç¬¬ 1 ç»´ DOF
        dof_state_reshaped = self.dof_state.view(self.num_envs, self.num_dof, 2)
        # channel 0 å­˜ position
        dof_state_reshaped[:, :, 0] = self.dof_pos
        # channel 1 å­˜ velocity
        dof_state_reshaped[:, :, 1] = self.dof_vel
        # ï¼ˆself.dof_state æœ¬èº«å› æ­¤ä¹Ÿè¢«æ›´æ–°ï¼‰

        # 6) å°†æ›´æ–°åçš„ dof_state å†™å›åˆ°ç‰©ç†å¼•æ“
        self.gym.set_dof_state_tensor_indexed(
            self.sim,
            gymtorch.unwrap_tensor(self.dof_state),
            gymtorch.unwrap_tensor(env_ids_int32),
            len(env_ids_int32)
        )

        # 7) é‡ç½®æ½œåœ¨ã€è¿›åº¦ç­‰ buffers
        to_target = self.targets[env_ids] - new_roots[:, 0:3]
        to_target[:, self.up_axis_idx] = 0.0
        self.prev_potentials[env_ids] = -torch.norm(to_target, p=2, dim=-1) / self.dt
        self.potentials[env_ids] = self.prev_potentials[env_ids].clone()

        self.progress_buf[env_ids] = 0
        self.reset_buf[env_ids] = 0

        # 8) æ¸…ç©ºä¸Šä¸€å¸§åŠ¨ä½œï¼Œé˜²æ­¢æœªå®šä¹‰
        self.actions[env_ids] = torch.zeros(
            (len(env_ids), self.num_actions),
            device=self.device
        )

        # ï¼ˆå¯é€‰ï¼‰è°ƒè¯•è¾“å‡º
        #print(f"[âœ… reset_idx] Finished resetting envs: {env_ids.tolist()}")

    def pre_physics_step(self, actions):
        self.actions = actions.to(self.device).clone()

        if not torch.all(torch.isfinite(self.actions)):
            print("ğŸš¨ Actions contain NaN! Sample:", self.actions[0])
            print("==> Shape:", self.actions.shape)
            raise ValueError("Actions contain NaN!")

        forces = self.actions * self.motor_efforts.unsqueeze(0) * self.power_scale
        force_tensor = gymtorch.unwrap_tensor(forces)
        self.gym.set_dof_actuation_force_tensor(self.sim, force_tensor)
    def post_physics_step(self):
        self.progress_buf += 1
        self.randomize_buf += 1

        env_ids = self.reset_buf.nonzero(as_tuple=False).flatten()
        if len(env_ids) > 0:
            self.reset_idx(env_ids)

        self.compute_observations()
        self.compute_reward(self.actions)
        root_pos = self.root_states[0, :3]  # Tensor([x, y, z])
        
        self.gym.refresh_actor_root_state_tensor(self.sim)
        # é‡æ–° wrap æŒ‡é’ˆ
        actor_root_state = self.gym.acquire_actor_root_state_tensor(self.sim)
        root_states = gymtorch.wrap_tensor(actor_root_state)

        # æ‰“å° Env0 çš„æ ¹ä½ç½®
        x, y, z = root_states[0, 0].item(), root_states[0, 1].item(), root_states[0, 2].item()
        print(f"[DEBUG] Env0 root position: x={x:.3f}, y={y:.3f}, z={z:.3f}")
        # debug viz
        if self.viewer and self.debug_viz:
            self.gym.clear_lines(self.viewer)

            points = []
            colors = []
            for i in range(self.num_envs):
                origin = self.gym.get_env_origin(self.envs[i])
                pose = self.root_states[:, 0:3][i].cpu().numpy()
                glob_pos = gymapi.Vec3(origin.x + pose[0], origin.y + pose[1], origin.z + pose[2])
                points.append([glob_pos.x, glob_pos.y, glob_pos.z, glob_pos.x + 4 * self.heading_vec[i, 0].cpu().numpy(),
                               glob_pos.y + 4 * self.heading_vec[i, 1].cpu().numpy(),
                               glob_pos.z + 4 * self.heading_vec[i, 2].cpu().numpy()])
                colors.append([0.97, 0.1, 0.06])
                points.append([glob_pos.x, glob_pos.y, glob_pos.z, glob_pos.x + 4 * self.up_vec[i, 0].cpu().numpy(), glob_pos.y + 4 * self.up_vec[i, 1].cpu().numpy(),
                               glob_pos.z + 4 * self.up_vec[i, 2].cpu().numpy()])
                colors.append([0.05, 0.99, 0.04])

            self.gym.add_lines(self.viewer, None, self.num_envs * 2, points, colors)

#####################################################################
###=========================jit functions=========================###
#####################################################################

from torch import Tensor
from typing import Tuple
@torch.jit.script
def compute_humanoid_reward(
    obs_buf:          Tensor,
    reset_buf:        Tensor,
    progress_buf:     Tensor,
    actions:          Tensor,
    up_weight:        float,
    heading_weight:   float,
    potentials:       Tensor,
    prev_potentials:  Tensor,
    actions_cost_scale:      float,
    energy_cost_scale:       float,
    joints_at_limit_cost_scale: float,
    max_motor_effort:        float,
    motor_efforts:           Tensor,
    termination_height:      float,
    death_cost:              float,
    max_episode_length:      int
) -> Tuple[Tensor, Tensor]:
    # è‡ªç”±åº¦æ•°ç›® = motor_efforts é•¿åº¦
    num_dof = motor_efforts.size(0)
    base   = 1 + 3 + 3 + 5  # torso_z + vel_loc(3) + angvel(3) + [yaw,roll,angle,up,heading]
    start  = base  # 12

    # åˆ‡å‡º pos, vel, forceï¼ˆæŒ‰ obs_buf ä¸­çš„æ‹¼æ¥é¡ºåºï¼‰
    pos   = obs_buf[:, start              : start + num_dof]
    vel   = obs_buf[:, start + num_dof    : start + 2 * num_dof]
    force = obs_buf[:, start + 2*num_dof  : start + 3 * num_dof]

    # â€”â€” åŸç‰ˆçš„åŠ¨ä½œæˆæœ¬ & æé™æˆæœ¬ â€”â€”
    heading_w  = torch.ones_like(obs_buf[:, 11]) * heading_weight
    heading_r  = torch.where(obs_buf[:, 11] > 0.8,
                              heading_w,
                              heading_weight * obs_buf[:, 11] / 0.8)
    up_r       = torch.where(obs_buf[:, 10] > 0.93,
                              torch.ones_like(heading_r) * up_weight,
                              torch.zeros_like(heading_r))
    actions_cost = torch.sum(actions ** 2, dim=-1)

    # å…³èŠ‚æé™æƒ©ç½š
    scaled_cost = joints_at_limit_cost_scale * (torch.abs(pos) - 0.98) / 0.02
    dof_limit_cost = torch.sum(
        (torch.abs(pos) > 0.98) * scaled_cost * (motor_efforts / max_motor_effort).unsqueeze(0),
        dim=-1
    )

    # èƒ½è€—æƒ©ç½šï¼ˆaction Ã— forceï¼‰
    electricity_cost = torch.sum(
        torch.abs(actions * force) * (motor_efforts / max_motor_effort).unsqueeze(0),
        dim=-1
    )

    alive_r    = torch.ones_like(potentials) * 2.0
    prog_r     = potentials - prev_potentials

    total = prog_r + alive_r + up_r + heading_r \
            - actions_cost_scale * actions_cost \
            - energy_cost_scale  * electricity_cost \
            - dof_limit_cost

    # æ‰è½æˆ–è¶…æ—¶é‡ç½®
    total = torch.where(obs_buf[:, 0] < termination_height,
                         torch.ones_like(total) * death_cost,
                         total)
    reset = torch.where(obs_buf[:, 0] < termination_height,
                        torch.ones_like(reset_buf),
                        reset_buf)
    reset = torch.where(progress_buf >= max_episode_length - 1,
                        torch.ones_like(reset_buf),
                        reset)
    return total, reset

@torch.jit.script
def compute_humanoid_observations(
    obs_buf: Tensor,
    root_states: Tensor,
    targets: Tensor,
    potentials: Tensor,
    inv_start_rot: Tensor,
    dof_pos: Tensor,
    dof_vel: Tensor,
    dof_force: Tensor,
    dof_limits_lower: Tensor,
    dof_limits_upper: Tensor,
    dof_vel_scale: float,
    sensor_force_torques: Tensor,
    actions: Tensor,
    dt: float,
    contact_force_scale: float,
    angular_velocity_scale: float,
    basis_vec0: Tensor,
    basis_vec1: Tensor,
) -> Tuple[Tensor, Tensor, Tensor, Tensor, Tensor]:
    """
    å·²é›†æˆâ€œæ–¹æ¡ˆä¸€â€å®‰å…¨æ‰©å±•ï¼š
    åŠ¨æ€è®¡ç®— safe_lowerã€safe_upperã€locked_dofsï¼Œ
    å¯¹é”æ­»å…³èŠ‚å½’ä¸€åŒ–ä¸º 0ï¼Œé¿å… inf/NaNã€‚
    """
    # â€”â€”â€” èº¯å¹²çŠ¶æ€ä¸é€Ÿåº¦ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    torso_position = root_states[:, 0:3]
    torso_rotation = root_states[:, 3:7]
    velocity       = root_states[:, 7:10]
    ang_velocity   = root_states[:, 10:13]

    # â€”â€”â€” åŠ¿èƒ½æ›´æ–° â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    to_target = targets - torso_position
    to_target[:, 2] = 0.0
    prev_potentials = potentials.clone()
    potentials = -torch.norm(to_target, p=2, dim=-1) / dt

    # â€”â€”â€” æœå‘ä¸æŠ•å½± â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    torso_quat, up_proj, heading_proj, up_vec, heading_vec = compute_heading_and_up(
        torso_rotation, inv_start_rot, to_target, basis_vec0, basis_vec1, 2
    )
    vel_loc, angvel_loc, roll, pitch, yaw, angle_to_target = compute_rot(
        torso_quat, velocity, ang_velocity, targets, torso_position
    )
    roll            = normalize_angle(roll).unsqueeze(-1)
    yaw             = normalize_angle(yaw).unsqueeze(-1)
    angle_to_target = normalize_angle(angle_to_target).unsqueeze(-1)

    # â€”â€”â€” æ–¹æ¡ˆä¸€ï¼šåŠ¨æ€æ„é€  safe_lower/safe_upper/locked_dofs â€”â€”
    locked_dofs = dof_limits_upper == dof_limits_lower
    eps: float   = 1e-6
    safe_lower  = dof_limits_lower
    # å¯¹é”æ­»å…³èŠ‚ä»…æ‰©å±•ä¸Šé™
    safe_upper  = dof_limits_upper + locked_dofs.to(dtype=dof_limits_upper.dtype) * eps

    # é’³åˆ¶å†å½’ä¸€åŒ–
    dof_pos_clamped = torch.max(
        torch.min(dof_pos, safe_upper.unsqueeze(0)),
        safe_lower.unsqueeze(0)
    )
    dof_pos_scaled = unscale(dof_pos_clamped, safe_lower, safe_upper)
    # é”æ­»å…³èŠ‚æ˜¾å¼ç½® 0
    dof_pos_scaled = torch.where(
        locked_dofs.unsqueeze(0),
        torch.zeros_like(dof_pos_scaled),
        dof_pos_scaled
    )

    # â€”â€”â€” ä¼ æ„Ÿå™¨è¡¥é›¶ & NaN/Inf æ£€æµ‹ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    if sensor_force_torques is None:
        sensor_force_torques = torch.zeros((dof_pos.shape[0], 0), device=dof_pos.device)
    # ï¼ˆå¯æŒ‰éœ€ä¿ç•™åŸæœ‰æ‰“å°ä¸ nan_to_numï¼‰

    # â€”â€”â€” æ‹¼æ¥ observation â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    obs = torch.cat((
        torso_position[:, 2:3],
        vel_loc,
        angvel_loc * angular_velocity_scale,
        yaw, roll, angle_to_target,
        up_proj.unsqueeze(-1), heading_proj.unsqueeze(-1),
        dof_pos_scaled,
        dof_vel * dof_vel_scale,
        dof_force * contact_force_scale,
        sensor_force_torques * contact_force_scale,
        actions
    ), dim=-1)

    return obs, potentials, prev_potentials, up_vec, heading_vec



